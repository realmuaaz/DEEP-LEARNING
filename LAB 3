
import numpy as np
import matplotlib.pyplot as plt

# Given values
A1 = np.array([[0.05], [0.10]])
W2 = np.array([[0.15, 0.20], [0.25, 0.30]])
W3 = np.array([[0.40, 0.45], [0.50, 0.55]])
b2 = np.array([[0.35], [0.35]])
b3 = np.array([[0.60], [0.60]])

# Given R vector
R = np.array([[0.01], [0.99]])

# Learning rate
alpha = 0.6

# Sigmoid activation function and its derivative
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return sigmoid(x) * (1 - sigmoid(x))

# Number of epochs
epochs = 6

# Initialize an array to store total errors
errors = np.zeros(epochs)

# Loop through epochs
for epoch in range(epochs):
    # Forward pass calculations
    Z2 = np.dot(W2, A1) + b2
    A2 = sigmoid(Z2)

    Z3 = np.dot(W3, A2) + b3
    A3 = sigmoid(Z3)

    # Calculate Deltas
    D3 = (A3 - R) * sigmoid_derivative(Z3)
    D2 = np.dot(W3.T, D3) * sigmoid_derivative(Z2)

    # Calculate gradients
    grad_W3 = np.dot(D3, A2.T)
    grad_b3 = D3
    grad_W2 = np.dot(D2, A1.T)
    grad_b2 = D2

    # Update weights and biases
    W2 = W2 - alpha * grad_W2
    b2 = b2 - alpha * grad_b2

    W3 = W3 - alpha * grad_W3
    b3 = b3 - alpha * grad_b3

    # Calculate total error and store in array
    total_error = np.sum((A3 - R) ** 2) / 2
    errors[epoch] = total_error

    # Print values for each epoch
    print(f"Epoch {epoch + 1}:")
    print("A2:", A2)
    print("A3:", A3)
    print("Z2:", Z2)
    print("Z3:", Z3)
    print("D2:", D2)
    print("D3:", D3)
    print("W2:", W2)
    print("W3:", W3)
    print("b2:", b2)
    print("b3:", b3)
    print("-" * 40)

# Plot the graph of total errors
plt.figure()
plt.plot(range(1, epochs + 1), errors, '-o')
plt.xlabel('Epochs')
plt.ylabel('Total Error')
plt.title('Total Error vs. Epochs')
plt.grid(True)
plt.show()

Epoch 1:
A2: [[0.59326999]
 [0.59688438]]
A3: [[0.75136507]
 [0.77292847]]
Z2: [[0.3775]
 [0.3925]]
Z3: [[1.10590597]
 [1.2249214 ]]
D2: [[0.00877135]
 [0.00995425]]
D3: [[ 0.13849856]
 [-0.03809824]]
W2: [[0.14973686 0.19947372]
 [0.24970137 0.29940274]]
W3: [[0.35069978 0.40039942]
 [0.51356152 0.56364415]]
b2: [[0.34473719]
 [0.34402745]]
b3: [[0.51690086]
 [0.62285894]]
----------------------------------------
Epoch 2:
A2: [[0.59198356]
 [0.59542849]]
A3: [[0.72370577]
 [0.77945423]]
Z2: [[0.3721714 ]
 [0.38645279]]
Z3: [[0.96291859]
 [1.2624887 ]]
D2: [[0.00759891]
 [0.0088505 ]]
D3: [[ 0.14270956]
 [-0.03619394]]
W2: [[0.14950889 0.19901778]
 [0.24943586 0.29887171]]
W3: [[0.30001075 0.34941542]
 [0.52641726 0.57657469]]
b2: [[0.34017784]
 [0.33871715]]
b3: [[0.43127513]
 [0.64457531]]
----------------------------------------
Epoch 3:
A2: [[0.59086806]
 [0.59413262]]
A3: [[0.69341657]
 [0.78552857]]
Z2: [[0.36755506]
 [0.38107611]]
Z3: [[0.816141  ]
 [1.29818028]]
D2: [[0.00615328]
 [0.00745213]]
D3: [[ 0.14528755]
 [-0.034448  ]]
W2: [[0.14932429 0.19864859]
 [0.24921229 0.29842459]]
W3: [[0.24850328 0.29762338]
 [0.53862979 0.5888547 ]]
b2: [[0.33648587]
 [0.33424587]]
b3: [[0.3441026 ]
 [0.66524411]]
----------------------------------------
Epoch 4:
A2: [[0.58996409]
 [0.59304048]]
A3: [[0.6608789 ]
 [0.79120943]]
Z2: [[0.36381695]
 [0.37654894]]
Z3: [[0.66721333]
 [1.33223102]]
D2: [[0.00449019]
 [0.00581098]]
D3: [[ 0.14587366]
 [-0.03283962]]
W2: [[0.14918959 0.19837918]
 [0.24903796 0.29807593]]
W3: [[0.19686715 0.24571799]
 [0.55025431 0.60053983]]
b2: [[0.33379176]
 [0.33075928]]
b3: [[0.2565784 ]
 [0.68494788]]
----------------------------------------
Epoch 5:
A2: [[0.58930406]
 [0.59218822]]
A3: [[0.62670438]
 [0.79654643]]
Z2: [[0.36108915]
 [0.37301877]]
Z3: [[0.51810431]
 [1.36484759]]
D2: [[0.00269906]
 [0.0040146 ]]
D3: [[ 0.14427552]
 [-0.03135113]]
W2: [[0.14910862 0.19821723]
 [0.24891753 0.29783505]]
W3: [[0.14585386 0.19445503]
 [0.56133952 0.61167929]]
b2: [[0.33217232]
 [0.32835052]]
b3: [[0.17001309]
 [0.70375856]]
----------------------------------------
Epoch 6:
A2: [[0.58890716]
 [0.5915991 ]]
A3: [[0.59168776]
 [0.80158088]]
Z2: [[0.35944947]
 [0.3705799 ]]
Z3: [[0.37094689]
 [1.39620433]]
D2: [[0.00088969]
 [0.00217362]]
D3: [[ 0.1405319 ]
 [-0.02996787]]
W2: [[0.14908193 0.19816385]
 [0.24885232 0.29770464]]
W3: [[0.09619772 0.1445719 ]
 [0.57192849 0.62231667]]
b2: [[0.3316385 ]
 [0.32704635]]
b3: [[0.08569395]
 [0.72173928]]
----------------------------------------
